//--------------------------------------------------------------------------
// Code generated by the SmartSoft MDSD Toolchain
// The SmartSoft Toolchain has been developed by:
//  
// Service Robotics Research Center
// University of Applied Sciences Ulm
// Prittwitzstr. 10
// 89075 Ulm (Germany)
//
// Information about the SmartSoft MDSD Toolchain is available at:
// www.servicerobotik-ulm.de
//
// This file is generated once. Modify this file to your needs. 
// If you want the toolchain to re-generate this file, please 
// delete it before running the code generator.
//--------------------------------------------------------------------------
#include "CaptureSensor.hh"
#include "InstanceRecognition.hh"

#include <iostream>

CaptureSensor::CaptureSensor(SmartACE::SmartComponent *comp) 
:	CaptureSensorCore(comp)
{
	std::cout << "constructor CaptureSensor\n";
}
CaptureSensor::~CaptureSensor() 
{
	std::cout << "destructor CaptureSensor\n";
}

void CaptureSensor::on_RGBDImagePushServiceIn(const DomainVision::CommRGBDImage &input)
{
	// upcall triggered from InputPort RGBDImagePushServiceIn
	// - use a local mutex here, because this upcal is called asynchroneously from outside of this task
	// - do not use longer blocking calls here since this upcall blocks the InputPort RGBDImagePushServiceIn
	// - if you need to implement a long-running procedure, do so within the on_execute() method and in
	//   there, use the method rGBDImagePushServiceInGetUpdate(input) to get a copy of the input object


	if(input.getColor_image().getDataSize() != 0){
		this->rGBImageObject = input.getColor_image();
		this->rGBImageObjectStatus = Smart::SMART_OK;
	}
	if(input.getDepth_image().getDataSize() != 0){
		this->depthImageObject = input.getDepth_image();
		this->depthImageObjectStatus = Smart::SMART_OK;
	}
}

int CaptureSensor::on_entry()
{
	// do initialization procedures here, which are called once, each time the task is started
	// it is possible to return != 0 (e.g. when initialization fails) then the task is not executed further
	return 0;
}
int CaptureSensor::on_execute()
{
	// TODO change to rGBDImagePushServiceInGetUpdate
	Smart::StatusCode status;
	cv::Mat ImageIn = COMP->getImageMat(this->rGBImageObject);
    std::vector<cv::KeyPoint> kp_test;
    cv::Mat test_dscr = extract_dscr(ImageIn, kp_test);

    std::vector< std::vector<cv::DMatch> > matches;
    std::vector<int>  match_ids = matching_db(test_dscr, matches);

    std::vector<box_obj> objects;

    for (int i = 0; i < match_ids.size(); ++i)
    {

        std::vector<cv::Point2f> obj;
        std::vector<cv::Point2f> scene;
        std::vector<cv::Point2f> obj_corners(4), scene_corners(4);
        box_obj box;

        for( size_t j = 0; j < matches[match_ids[i]].size(); j++ )
        {
            obj.push_back( db_kp[match_ids[i]][ matches[match_ids[i]][j].queryIdx ].pt );
            scene.push_back( kp_test[matches[match_ids[i]][j].trainIdx].pt );
        }

        cv::Mat H =  cv::findHomography( obj, scene, cv::RANSAC );

        obj_corners[0] = cvPoint(0,0); obj_corners[1] = cvPoint( db_width[match_ids[i]], 0 );
        obj_corners[2] = cvPoint( db_width[match_ids[i]], db_heigth[match_ids[i]] ); obj_corners[3] = cvPoint( 0, db_heigth[match_ids[i]] );

        cv::perspectiveTransform( obj_corners, scene_corners, H);
        box.p1 = scene_corners[0]; box.p2 = scene_corners[1];
        box.p3 = scene_corners[2]; box.p4 = scene_corners[3];
        objects.push_back(box);
    }

    std::vector<cv::Rect> objs_rects;
    remove_duplicates(objects, objs_rects);

    //Saving data
    detected_imgs.clear();
    detected_label.clear();
    detected_roi.clear();
    for (int i = 0; i < objects.size(); ++i)
    {
        cv::line( ImageIn, objects[i].p1, objects[i].p2, cv::Scalar(255, 0, 0), 4 );
        cv::line( ImageIn, objects[i].p2, objects[i].p3, cv::Scalar( 255, 0, 0), 4 );
        cv::line( ImageIn, objects[i].p3, objects[i].p4, cv::Scalar( 255, 0, 0), 4 );
        cv::line( ImageIn, objects[i].p4, objects[i].p1, cv::Scalar( 255, 0, 0), 4 );

        detected_imgs.push_back( ImageIn(objs_rects[i]) );
        detected_label.push_back (db_label[match_ids[i]]);

        CommPerception::Box obj_roi;

        point_to_position(objects[i].p1, obj_roi.getP1());
        point_to_position(objects[i].p2, obj_roi.getP2());
        point_to_position(objects[i].p3, obj_roi.getP3());
        point_to_position(objects[i].p4, obj_roi.getP4());
        detected_roi.push_back (obj_roi);
    }

    cv::imshow("InstanceRecognition", ImageIn);
    cv::waitKey(5);
}

	return 0;
}
int CaptureSensor::on_exit()
{
	// use this method to clean-up resources which are initialized in on_entry() and needs to be freed before the on_execute() can be called again
	return 0;
}

bool CaptureSensor::load_database() {
	std::stringstream path_db;
	path_db<<db_path<<"/manipulable_objects/Objects";

    path directory_train(path_db.str());

    directory_iterator end_it;
    file_status f = status(directory_train);

    if (!(f.type() != status_unknown && f.type() != file_not_found))
    	std::cout << "Training directory not found"<< std::endl;

   // bool only_one = false;
    for( directory_iterator it( directory_train ); it != end_it; it++ ) {
        if ( is_directory( it->status() ) )
        {


            std::stringstream path_obj;
            path_obj<<path_db.str()<<"/"<<it->path().filename().c_str();
            path obj(path_obj.str());

            std::string name_object = it->path().filename().c_str();

            int n_imgs=0;
            for( directory_iterator it2( obj ); it2 != end_it; it2++ ) {
                if( is_regular_file( it2->status()) && (it2->path().extension() == ".jpg" || it2->path().extension() == ".png"))
                {
                    std::stringstream path_img;
                    std::string img=it2->path().filename().c_str();
                    path_img<<path_obj.str()<<"/"<<img;
                    std::cout << "file "<<path_img.str()<< std::endl;

                    cv::Mat mat_img = cv::imread(path_img.str(), CV_LOAD_IMAGE_COLOR);
                    std::vector<cv::KeyPoint> kp;
                    cv::Mat dscr = extract_dscr(mat_img, kp);
                    db_kp.push_back(kp);
                    db_dscr.push_back(dscr);
                    db_label.push_back(name_object);
                    db_heigth.push_back(mat_img.rows);
                    db_width.push_back(mat_img.cols);

                    train_succes = true;
                    n_imgs ++;
                }
            }
            std::cout <<"Object "+name_object+". . . "<< n_imgs <<" Images Trained"<< std::endl;

        }

    }


    if (train_succes)
    {
    	std::cout <<"Training Success. "<<db_label.size()<< " Images in Total"<< std::endl;
    }
    else
    	std::cout <<"Training Failed. Please check the directory: "<<path_db.str()<< std::endl;

    _is_on = false;

    return true;

}

cv::Mat CaptureSensor::extract_dscr(cv::Mat image_input, std::vector<cv::KeyPoint> &kp) {

    cv::Mat dscr;
//
//    if (_algorithm == recognition_alg[0]) {
//        cv::Mat img_lbp;
//        lbp->run(image_input, img_lbp);
//        cv::normalize(img_lbp, img_lbp, 0, 255, cv::NORM_MINMAX, CV_8UC1);
//
//        dscr = get_histogram(img_lbp);
//    }
//    else {
        detector->detect(image_input, kp);
        extractor->compute(image_input, kp, dscr);
//    }

    return dscr;
}

std::vector<int> CaptureSensor::matching_db(cv::Mat dscr_input, std::vector< std::vector<cv::DMatch> > &matches) {

    const float ratio_thresh = 0.7f;
    std::vector<int> n_matches, id_matches;

//    if (_algorithm == recognition_alg[0] || _algorithm == recognition_alg[1]){
//        int best_match = 0, best_id;
//        for (int i = 0; i < db_dscr.size(); ++i)
//        {
//            double value_match;
//            if(_compare_hist == compare_hist_methods[0]) value_match = cv::compareHist(db_dscr[i], dscr_input, CV_COMP_CORREL);
//            if(_compare_hist == compare_hist_methods[1]) value_match = cv::compareHist(db_dscr[i], dscr_input, CV_COMP_CHISQR);
//            if(_compare_hist == compare_hist_methods[2]) value_match = cv::compareHist(db_dscr[i], dscr_input, CV_COMP_INTERSECT);
//            if(_compare_hist == compare_hist_methods[3]) value_match = cv::compareHist(db_dscr[i], dscr_input, CV_COMP_BHATTACHARYYA);
//
//            if (value_match > best_match)
//            {
//                best_match = value_match;
//                best_id = i;
//            }
//        }
//        if (best_match > 0.5)//confirm
//            id_matches.push_back(best_id);
//
//        return id_matches;
//    }


    int best_match = 0, best_id;
    for (int i = 0; i < db_dscr.size(); ++i)
    {
        std::vector< std::vector<cv::DMatch> > knn_matches;
        std::vector<cv::DMatch> good_matches;
        matcher->knnMatch( db_dscr[i], dscr_input, knn_matches, 2 ); //2?

        for (size_t j = 0; j < knn_matches.size(); j++)
        {
            if (knn_matches[j][0].distance < ratio_thresh * knn_matches[j][1].distance)
                good_matches.push_back(knn_matches[j][0]);
        }
        matches.push_back(good_matches);

        if (good_matches.size() > best_match)
        {
             best_match = good_matches.size();
             best_id = i;
        }
        n_matches.push_back(good_matches.size());
    }

    //Printing matching information
    //std::cout<<"best match: "<<db_label[best_id]<<std::endl;
    for (int i = 0; i < n_matches.size(); ++i)
        if (n_matches[i] >= 9){
         //   std::cout<<"match: "<<db_label[i] <<" - "<< n_matches[i]<<std::endl;
            id_matches.push_back(i);
        }


    return id_matches;

}

void CaptureSensor::remove_duplicates(std::vector<box_obj> &objs, std::vector<cv::Rect> &objs_rects){
    for (int i = 1; i < objs.size(); ++i)
    {
        cv::Rect r1 = cv::Rect(std::min(objs[i].p1.x, objs[i].p3.x), std::min(objs[i].p1.y, objs[i].p3.y), std::max(objs[i].p2.x, objs[i].p4.x) - std::min(objs[i].p1.x, objs[i].p3.x), std::max(objs[i].p2.y, objs[i].p4.y) - std::min(objs[i].p1.y, objs[i].p3.y));
        for (int j = 0; j < i; ++j)
        {
            cv::Rect r2 = cv::Rect(std::min(objs[j].p1.x, objs[j].p3.x), std::min(objs[j].p1.y, objs[j].p3.y), std::max(objs[j].p2.x, objs[j].p4.x) - std::min(objs[j].p1.x, objs[j].p3.x), std::max(objs[j].p2.y, objs[j].p4.y) - std::min(objs[j].p1.y, objs[j].p3.y));

            cv::Rect intersection = r1 & r2;
            if (intersection.width * intersection.height > r1.width * r1.height * 0.4){
                if (r1.width * r1.height > r2.width * r2.height ) objs.erase(objs.begin() + i);
                else objs.erase(objs.begin() + j);

                i--;
                continue;
            }
        }
    }

    for (int i = 0; i < objs.size(); ++i)
    {
        cv::Rect r1 = cv::Rect(std::min(objs[i].p1.x, objs[i].p3.x), std::min(objs[i].p1.y, objs[i].p3.y), std::max(objs[i].p2.x, objs[i].p4.x) - std::min(objs[i].p1.x, objs[i].p3.x), std::max(objs[i].p2.y, objs[i].p4.y) - std::min(objs[i].p1.y, objs[i].p3.y));
        objs_rects.push_back(r1);
    }

}

void CaptureSensor::point_to_position(cv::Point point2d, CommBasicObjects::CommPosition3d &point3d){

	point3d.setX(point2d.x).setY(point2d.y);
}


CommBasicObjects::CommPose3d CaptureSensor::point2d_to_pose(cv::Point point_in){
	cv::Mat DepthIn =  COMP->getDepthImageMat(this->depthImageObject);
      if(! DepthIn.data || DepthIn.cols==0 || DepthIn.rows==0)
        std::cout<<"geometry_msgs::PoseStamped InstanceRecognition::point2d_to_pose() : depth image null"<<std::endl;


    CommBasicObjects::CommPose3d pose_out;

    float fx = colorcamera_info[0], fy = colorcamera_info[1];
    float cx = colorcamera_info[2], cy = colorcamera_info[3];

    uint16_t z_raw = DepthIn.at<uint16_t>(point_in.y, point_in.x);
    pose_out.position.z = z_raw * 0.001;
    pose_out.position.x = (point_in.x - cx) * pose_out.position.z / fx;
    pose_out.position.y = (point_in.y - cy) * pose_out.position.z / fy;
    pose_out.orientation.w = 1;

    return pose_out;

}

